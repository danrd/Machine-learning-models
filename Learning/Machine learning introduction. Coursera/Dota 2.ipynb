{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dota 2 — многопользовательская компьютерная игра жанра MOBA. Игроки играют между собой матчи. \n",
    "В каждом матче, как правило, участвует 10 человек. Матчи формируются из живой очереди, с учётом уровня игры всех игроков. \n",
    "Перед началом игры игроки автоматически разделяются на две команды по пять человек. \n",
    "Одна команда играет за светлую сторону (The Radiant), другая — за тёмную (The Dire). \n",
    "Цель каждой команды — уничтожить главное здание базы противника, трон.\n",
    "\n",
    "Вам нужно построить модель, которая по данным о первых пяти минутах матча будет предсказывать его исход — то есть определять команду-победителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Подход 1: градиентный бустинг \"в лоб\"\n",
    "Решаемые задачи:    \n",
    "1. Какие признаки имеют пропуски среди своих значений (приведите полный список имен этих признаков)? \n",
    "Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?\n",
    "2. Как называется столбец, содержащий целевую переменную?\n",
    "3. Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? \n",
    "Инструкцию по измерению времени можно найти выше по тексту. Какое качество при этом получилось?\n",
    "4. Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? \n",
    "Что можно сделать, чтобы ускорить его обучение при увеличении количества деревьев?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#пункты задания 1-4 подхода 1\n",
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "y_train = features[\"radiant_win\"] #извлекаем целевую переменную и отбрасываем итоговые признаки\n",
    "x_train_orig = features.iloc[:, 0:-6]\n",
    "count = x_train_orig.count() #считаем число наблюдений по признакам\n",
    "features_with_na = count[count<len(x_train_orig)] #отбираем признаки с пропусками\n",
    "na_sum = sum(len(x_train_orig)-features_with_na) #суммарное число пропусков по признакам\n",
    "x_train = x_train_orig.fillna(0) #заменяем пропуски в данных на нули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:02:01.653958\n",
      "AUC-ROC: 0.6900064710388155\n"
     ]
    }
   ],
   "source": [
    "#пункт задания 5 подхода 1, вариант для 30 деревьев с замером времени\n",
    "clf = GradientBoostingClassifier(n_estimators=30, random_state=42) #задаем классификатор \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "start_time = datetime.datetime.now() #оценивание модели с замером времени \n",
    "score = cross_val_score(estimator=clf, cv=cv, X=x_train, y=y_train, scoring=\"roc_auc\")\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time) \n",
    "print(\"AUC-ROC:\", (np.mean(score))) #вывод средней метрики по 5 блокам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:02:03.809081\n",
      "AUC-ROC: 0.689975068812293\n"
     ]
    }
   ],
   "source": [
    "#дополнительный вариант с заполнением пропущенных значений по минимальному значению\n",
    "x_train_na_min = x_train_orig.apply(lambda x: x.fillna(min(x)), axis=1)\n",
    "clf = GradientBoostingClassifier(n_estimators=30, random_state=42) #задаем классификатор \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "start_time = datetime.datetime.now() #оценивание модели с замером времени  \n",
    "score = cross_val_score(estimator=clf, cv=cv, X=x_train_na_min, y=y_train, scoring=\"roc_auc\")\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time) \n",
    "print(\"AUC-ROC:\", (np.mean(score))) #вывод средней метрики по 5 блокам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:02:10.309453\n",
      "AUC-ROC: 0.6899747563380221\n"
     ]
    }
   ],
   "source": [
    "#дополнительный вариант с заполнением пропущенных значений по среднему значению\n",
    "x_train_na_mean = x_train_orig.apply(lambda x: x.fillna(np.mean(x)), axis=1)\n",
    "clf = GradientBoostingClassifier(n_estimators=30, random_state=42) #задаем классификатор \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "start_time = datetime.datetime.now() #оценивание модели с замером времени   \n",
    "score = cross_val_score(estimator=clf, cv=cv, X=x_train_na_mean, y=y_train, scoring=\"roc_auc\")\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time) \n",
    "print(\"AUC-ROC:\", (np.mean(score))) #вывод средней метрики по 5 блокам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#пункт задания 5 подхода 1, вариант с подбором числа деревьев с помощью GridSearchCV\n",
    "clf = GradientBoostingClassifier(random_state=42) #задаем классификатор \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации \n",
    "param = {'n_estimators': list(range(10, 101, 10))}\n",
    "grid = GridSearchCV(estimator=clf, cv=cv, scoring=\"roc_auc\", param_grid=param)\n",
    "grid.fit(x_train, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Подведение итога для подхода 1:\n",
    "    \n",
    "1. Пропуски имеют следующие признаки:\n",
    "\n",
    "first_blood_time first_blood_team first_blood_player1 first_blood_player2 radiant_bottle_time radiant_courier_time radiant_flying_courier_time radiant_first_ward_time dire_bottle_time dire_courier_time dire_flying_courier_time dire_first_ward_time\n",
    "\n",
    "Обоснование по группам признаков:\n",
    "\n",
    "first_blood_... - возможны как игры без убийств в первые 5 минут, так и без убийств вообще. Что, например, может быть связано с преднамеренной сдачей игры одной из сторон посредством выхода всех ее игроков или дисконнектом всех участников по техническим причинам.\n",
    "\n",
    "first_blood_player2 - меньше остальных из группы в связи с тем, что если убийство и было, то в нем может участвовать только 1 игрок.\n",
    "\n",
    "..._bottle_time - возможны игры с покупкой этого предмета позже или вообще без него\n",
    "\n",
    "..._courier_time -возможны игры с покупкой курьера позже или вообще без него\n",
    "\n",
    "..._flying_courier_time - к играм без курьера в первые 5 минут добавляются те, где он не был улучшен за это время\n",
    "\n",
    "..._first_ward_time - игры без установки вардов в первые 5 минут или вообще\n",
    "\n",
    "2. столбец \"radiant_win\", позволяющий установить результат игры, что и требуется предсказать.\n",
    "\n",
    "3. Время для 30 деревьев: Time elapsed: 0:02:01\n",
    "\n",
    "Качество : AUC-ROC: 0.69\n",
    "\n",
    "4. GridSearch по числу деревьев от 10 до 100 показывает, что лучшее качество достигается именно при 100 деревьях, \n",
    "так что увеличение числа деревьев может иметь смысл. Однако разница по метрике AUC-ROC с моделью по 30 деревьям \n",
    "составляет всего около 0.016, так что для улучшения модели, вероятно, следует рассматривать другие способы. \n",
    "\n",
    "Возможные варианты ускорения обучения модели:\n",
    "\n",
    "уменьшение числа используемых признаков\n",
    "нормализация значений признаков\n",
    "изменение параметров классификатора (коэффициента скорости обучения, минимального числа наблюдений для ветвления, минимального числа наблюдений в листе дерева, итд)\n",
    "изменение параметров кросс-валидации (например, уменьшение числа блоков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Подход 2: логистическая регрессия\n",
    "Решаемые задачи:  \n",
    "1. Какое качество получилось у логистической регрессии над всеми исходными признаками? \n",
    "Как оно соотносится с качеством градиентного бустинга? Чем можно объяснить эту разницу? \n",
    "Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "2. Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? \n",
    "Чем можно объяснить это изменение?\n",
    "3. Сколько различных идентификаторов героев существует в данной игре?\n",
    "4. Какое получилось качество при добавлении \"мешка слов\" по героям? \n",
    "Улучшилось ли оно по сравнению с предыдущим вариантом? Чем можно это объяснить?\n",
    "5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пункт задания 1 подхода 2, предобработка\n",
    "scaler = StandardScaler()\n",
    "scaled = pd.DataFrame(scaler.fit_transform(x_train)) #стандартизируем признаки и оборачиваем в df\n",
    "scaled.columns = x_train.columns #возвращаем исходные названия признаков\n",
    "x_train_scaled = scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пункт задания 1 подхода 2, GridSearch\n",
    "reg = LogisticRegression(penalty=\"l2\", random_state=42) #задаем классификатор\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "param = {'C': [0.001, 0.05, 0.5, 1, 5, 10, 25, 50, 100, 1000]} #задаем варианты для параметра C\n",
    "grid = GridSearchCV(estimator=reg, cv=cv, scoring=\"roc_auc\", param_grid=param)\n",
    "grid.fit(x_train_scaled, y_train)\n",
    "grid.best_estimator_ #узнаем лучший параметр C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:05.149295\n",
      "AUC-ROC: 0.7165312477339544\n"
     ]
    }
   ],
   "source": [
    "# пункт задания 1 подхода 2, проверка качества и скорости с лучшим параметром С по нормализованной выборке\n",
    "reg = LogisticRegression(penalty=\"l2\", C=0.05, random_state=42) #задаем классификатор\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "start_time = datetime.datetime.now() #оценивание модели с замером времени \n",
    "score = cross_val_score(estimator=reg, cv=cv, X=x_train_scaled, y=y_train, scoring=\"roc_auc\")\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time) \n",
    "print(\"AUC-ROC:\", (np.mean(score))) #вывод средней метрики по 5 блокам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:01.869107\n",
      "AUC-ROC: 0.513447617665222\n"
     ]
    }
   ],
   "source": [
    "# пункт задания 1 подхода 2, проверка качества и скорости с лучшим параметром С по исходной выборке\n",
    "reg = LogisticRegression(penalty=\"l2\", C=0.05, random_state=42) #задаем классификатор\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "start_time = datetime.datetime.now() #оценивание модели с замером времени \n",
    "score = cross_val_score(estimator=reg, cv=cv, X=x_train, y=y_train, scoring=\"roc_auc\")\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time) \n",
    "print(\"AUC-ROC:\", (np.mean(score))) #вывод средней метрики по 5 блокам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пункт задания 2 подхода 2, исключение категориальных признаков\n",
    "columns_drop = x_train.filter(regex='_hero$', axis=1).columns\n",
    "x_train_cleaned = x_train.drop(columns_drop, axis=1)\n",
    "x_train_cleaned = x_train_cleaned.drop(\"lobby_type\", axis=1)\n",
    "x_train_scaled_cleaned = x_train_scaled.drop(columns_drop, axis=1)\n",
    "x_train_scaled_cleaned = x_train_scaled_cleaned.drop(\"lobby_type\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пункт задания 2 подхода 2, GridSearch\n",
    "reg = LogisticRegression(penalty=\"l2\", random_state=42) #задаем классификатор\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "param = {'C': [0.001, 0.05, 0.5, 1, 5, 10, 25, 50, 100, 1000]} #задаем варианты для параметра C\n",
    "grid = GridSearchCV(estimator=reg, cv=cv, scoring=\"roc_auc\", param_grid=param)\n",
    "grid.fit(x_train_scaled_cleaned, y_train)\n",
    "grid.best_estimator_ #узнаем лучший параметр C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:07.394423\n",
      "AUC-ROC: 0.7165372973746911\n"
     ]
    }
   ],
   "source": [
    "# пункт задания 2 подхода 2, проверка качества и скорости с лучшим параметром С\n",
    "reg = LogisticRegression(penalty=\"l2\", C=0.05, random_state=42) #задаем классификатор\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "start_time = datetime.datetime.now() #оценивание модели с замером времени \n",
    "score = cross_val_score(estimator=reg, cv=cv, X=x_train_scaled_cleaned, y=y_train, scoring=\"roc_auc\")\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time) \n",
    "print(\"AUC-ROC:\", (np.mean(score))) #вывод средней метрики по 5 блокам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пункт задания 3 подхода 2\n",
    "heroes = x_train.filter(regex='_hero$', axis=1) #отбираем признаки с выбранными героями\n",
    "unique, counts= np.unique(heroes.values.flatten(), return_counts=True) #и их уникальные значения\n",
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пункт задания 4 подхода 2, извлекаем индексы признаков по героям для создания \"мешка слов\"\n",
    "columns = x_train.filter(regex='_hero$', axis=1).columns #отбор имен признаков по героям \n",
    "r_loc = [0]*len(columns[0:5]) #колонки героев света\n",
    "d_loc = [0]*len(columns[5:10]) #колонки героев тьмы\n",
    "for i, col in enumerate(columns[0:5]): #индексы колонок героев света\n",
    "    r_loc[i] = x_train.keys().get_loc(col)\n",
    "for i, col in enumerate(columns[5:10]): #индексы колонок героев тьмы\n",
    "    d_loc[i] = x_train.keys().get_loc(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пункт задания 4 подхода 2, создание \"мешка слов\"\n",
    "X_pick = np.zeros((x_train.shape[0], max(unique)))\n",
    "for i in range(len(x_train)):\n",
    "    for p in range(5):\n",
    "        X_pick[i, x_train.iloc[i, r_loc[p]]-1] = 1\n",
    "        X_pick[i, x_train.iloc[i, d_loc[p]]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пункт задания 4 подхода 2, добавление \"мешка слов\" к данным без категориальных признаков\n",
    "x_heroes = pd.DataFrame(X_pick) #оборачиваем \"мешок слов\" в дата фрейм\n",
    "names = [0]*len(x_heroes.columns) #создаем имена для переменных по героям\n",
    "for i in range(len(x_heroes.columns)):\n",
    "    names[i] = \"hero_\"+str(i+1)\n",
    "x_heroes.columns = names\n",
    "x_heroes = x_heroes.set_index(x_train_scaled_cleaned.index.values) #слияние данных по индексу\n",
    "x_with_heroes = x_train_scaled_cleaned.join(x_heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пункт задания 5 подхода 2, GridSearch\n",
    "reg = LogisticRegression(penalty=\"l2\", random_state=42, max_iter=1000) #задаем классификатор\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "param = {'C': [0.001, 0.05, 0.5, 1, 5, 10, 25, 50, 100, 1000]} #задаем варианты для параметра C\n",
    "grid = GridSearchCV(estimator=reg, cv=cv, scoring=\"roc_auc\", param_grid=param)\n",
    "grid.fit(x_with_heroes, y_train)\n",
    "grid.best_estimator_ #узнаем лучший параметр C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:19.590120\n",
      "AUC-ROC: 0.7519498731973165\n"
     ]
    }
   ],
   "source": [
    "# пункт задания 5 подхода 2, проверка качества и скорости с лучшим параметром С\n",
    "reg = LogisticRegression(penalty=\"l2\", C=0.05, random_state=42, max_iter=1000) #задаем классификатор\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #и модель кросс-валидации\n",
    "start_time = datetime.datetime.now() #оценивание модели с замером времени \n",
    "score = cross_val_score(estimator=reg, cv=cv, X=x_with_heroes, y=y_train, scoring=\"roc_auc\")\n",
    "print('Time elapsed:', datetime.datetime.now() - start_time) \n",
    "print(\"AUC-ROC:\", (np.mean(score))) #вывод средней метрики по 5 блокам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пункт задания 6 подхода 2, предобработка тестовых данных\n",
    "features_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "x_test = features_test.fillna(0) #заполняем пропуски\n",
    "\n",
    "#нормализация\n",
    "scaler = StandardScaler()\n",
    "scaled = pd.DataFrame(scaler.fit_transform(x_test)) #стандартизируем признаки и оборачиваем в df\n",
    "scaled.columns = x_test.columns #возвращаем исходные названия признаков\n",
    "x_test_scaled = scaled\n",
    "\n",
    "#исключение категориальных признаков\n",
    "columns_drop = x_train.filter(regex='_hero$', axis=1).columns\n",
    "x_test_scaled_cleaned = x_test_scaled.drop(columns_drop, axis=1)\n",
    "x_test_scaled_cleaned = x_test_scaled_cleaned.drop(\"lobby_type\", axis=1)\n",
    "\n",
    "#создание \"мешка слов\"\n",
    "X_pick = np.zeros((x_test.shape[0], max(unique))) #используем значения, определенные ранее\n",
    "for i in range(len(x_test)):\n",
    "    for p in range(5):\n",
    "        X_pick[i, x_train.iloc[i, r_loc[p]]-1] = 1\n",
    "        X_pick[i, x_train.iloc[i, d_loc[p]]-1] = -1\n",
    "\n",
    "#присоединение \"мешка слов\" к данным     \n",
    "x_heroes = pd.DataFrame(X_pick) #оборачиваем \"мешок слов\" в дата фрейм\n",
    "names = [0]*len(x_heroes.columns) #создаем имена для переменных по героям\n",
    "for i in range(len(x_heroes.columns)):\n",
    "    names[i] = \"hero_\"+str(i+1)\n",
    "x_heroes.columns = names\n",
    "x_heroes = x_heroes.set_index(x_test_scaled_cleaned.index.values) #слияние данных по индексу\n",
    "x_test_with_heroes = x_test_scaled_cleaned.join(x_heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пункт задания 6 подхода 2, прогноз по тестовым данным\n",
    "reg = LogisticRegression(penalty=\"l2\", C=0.05, random_state=42, max_iter=1000) #задаем классификатор\n",
    "reg.fit(x_with_heroes, y_train) #подгонка модели по тренировочным данным\n",
    "y_pred = reg.predict_proba(x_test_with_heroes) #прогноз классов\n",
    "r_win = y_pred[:,1] #прогноз класса 1 - победы светлой стороны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975963558459781"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(r_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004777206936445505"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(r_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Подведение итога для подхода 2:\n",
    "    \n",
    "1. AUC-ROC модели составил 0.51, что почти на 0.2 хуже лучшей модели градиентного бустинга. \n",
    "Такой результат может объясняться универсальностью градиентного бустинга при работе с признаками: применение логистической регрессии к исходной выборке без отбора признаков не позволяет получить достаточно хороший результат. \n",
    "Так, при использовании нормализации данных логистическая регрессия достигает значения AUC-ROC 0.717, что лучше примененных \"в лоб\" моделей градиентного бустинга.\n",
    "По скорости работы логистическая регрессия имеет большое преимущество против градиентного бустинга: не более 5 секунд по сравнению с примерно 2 минутами. \n",
    "Линейные методы в целом являются одними из наиболее быстрых, в данном же случае также можно отметить наличие большого числа \n",
    "порядковых и категориальных переменных в выборке, а также степень разряженности данных (нулевых значений, в том числе за счет заполнения пропущенных данных), \n",
    "что нормально для логистической регрессии, но может замедлять градиентный бустинг.\n",
    "\n",
    "2. После удаления категориальных признаков значение метрики качества незначительно улучшилось - AUC-ROC=0.716537 против 0.716531 до удаления.\n",
    "Так как в линейных моделях каждому признаку соответствует некоторый коэффициент, с которым значение признака входит \n",
    "в сумму и который можно интерпретировать по его абсолютной величине как значимость признака, то, вероятно, \n",
    "данные категориальные признаки не учитывались в модели в силу их малой информативности.\n",
    "\n",
    "3. 112 героев, но в выборке использовалось только 108 \n",
    "\n",
    "4. После добавления \"мешка слов\" AUC-ROC составил 0.7519, что в сравнении со значением 0.7165 говорит об ощутимом улучшении качества модели. \n",
    "Из этого можно сделать вывод, что состав команды в разрезе героев является информативным для определения победителя - \n",
    "некоторые герои побеждают значимо чаще.\n",
    "\n",
    "5. Минимальное значение прогноза=0.0048; Максимальное значение прогноза=0.9976."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
