{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import re\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "#!python -m spacy download en\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, ToktokTokenizer, RegexpTokenizer\n",
    "\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim import corpora\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучающих текстов 11314\n",
      "Количество тестовых текстов 7532\n",
      "\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "Метка 7\n"
     ]
    }
   ],
   "source": [
    "train_source = fetch_20newsgroups(subset='train')\n",
    "test_source = fetch_20newsgroups(subset='test')\n",
    "\n",
    "print('Количество обучающих текстов', len(train_source['data']))\n",
    "print('Количество тестовых текстов', len(test_source['data']))\n",
    "\n",
    "print()\n",
    "print(train_source['data'][0].strip())\n",
    "\n",
    "\n",
    "print()\n",
    "print('Метка', train_source['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus, whitespaces=True, punctuation=True, numbers=True):\n",
    "    corpus = re.sub(r\"[^a-zA-Z0-9.?! ]+\", \" \", corpus.lower().strip()) \n",
    "    if whitespaces == True:\n",
    "        corpus = re.sub(r\"[' ']{2,}\", \" \", corpus)\n",
    "    if punctuation == True:\n",
    "        corpus = re.sub(r\"[,.!?:;%]+\", \" \", corpus)\n",
    "    if numbers == True:\n",
    "        corpus = re.sub(r\"[0-9]+\", \"\", corpus)        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from lerxst wam umd edu where s my thing subject what car is this  nntp posting host rac wam umd edu organization university of maryland college park lines  i was wondering if anyone out there could enlighten me on this car i saw the other day  it was a  door sports car looked to be from the late s early s  it was called a bricklin  the doors were really small  in addition the front bumper was separate from the rest of the body  this is all i know  if anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please e mail  thanks il brought to you by your neighborhood lerxst '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(train_source['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing spacy tokenizer adding stopwords from nltk\n",
    "nlp = English()\n",
    "nlp.Defaults.stop_words |= set(stopwords.words('english')) - set(nlp.Defaults.stop_words)\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing and following tokenization \n",
    "train_tokens = [list(map(str, tokenizer(preprocess(sentence)))) for sentence in train_source['data']]\n",
    "test_tokens = [list(map(str, tokenizer(preprocess(sentence)))) for sentence in test_source['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing sklearn TfidfVectorizer\n",
    "max_df = 0.80\n",
    "min_df = 0.01\n",
    "counter = CountVectorizer(preprocessor=preprocess, max_df=max_df, \n",
    "                             min_df=min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter.fit_transform(train_source['data']+test_source['data'])\n",
    "vocab = counter.vocabulary_\n",
    "vectorizer = TfidfVectorizer(preprocessor=preprocess, max_df=max_df, \n",
    "                             min_df=min_df, vocabulary=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf transform\n",
    "train_vectors = vectorizer.fit_transform(train_source['data'])\n",
    "test_vectors = vectorizer.fit_transform(test_source['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность матрицы признаков обучающей выборки (11314, 2035)\n",
      "Размерность матрицы признаков тестовой выборки (7532, 2035)\n",
      "\n",
      "Количество ненулевых элементов в обучающей выборке 1039018\n",
      "Процент заполненности матрицы признаков 4.51%\n",
      "\n",
      "Количество ненулевых элементов в тестовой выборке 684323\n",
      "Процент заполненности матрицы признаков 4.46%\n"
     ]
    }
   ],
   "source": [
    "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
    "print('Размерность матрицы признаков тестовой выборки', test_vectors.shape)\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
    "print()\n",
    "print('Количество ненулевых элементов в тестовой выборке', test_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(test_vectors.nnz * 100 / (test_vectors.shape[0] * test_vectors.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_vectors.data, bins=20)\n",
    "plt.title('Распределение весов признаков')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_clf = DecisionTreeClassifier(random_state=42)\n",
    "random_clf = RandomForestClassifier(random_state=42)\n",
    "gradient_clf = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5293414763674986"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_clf.fit(train_vectors, train_source['target'])\n",
    "trees_clf.score(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7002124269782263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_clf .fit(train_vectors, train_source['target'])\n",
    "random_clf .score(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6818906001062135"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_clf .fit(train_vectors, train_source['target'])\n",
    "gradient_clf .score(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266330323951142"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = LinearSVC(random_state=42)\n",
    "svm_clf.fit(train_vectors, train_source['target'])\n",
    "svm_clf.score(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7328730748805098"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression(random_state=42)\n",
    "logistic_clf.fit(train_vectors, train_source['target'])\n",
    "logistic_clf.score(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary by gensim\n",
    "train_dic = corpora.Dictionary(train_tokens)\n",
    "train_dic.filter_extremes(no_below=5, no_above=0.5)\n",
    "freqs = [pair[1] for pair in train_dic.most_common(len(train_dic))]\n",
    "bow = [train_dic.doc2bow(sentence) for sentence in train_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf calculation\n",
    "tfidf = models.TfidfModel(bow)\n",
    "corpus_tfidf = tfidf[bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda topic modeling\n",
    "lda = models.LdaModel(corpus=bow, num_topics=20, id2word=train_dic)\n",
    "doc_lda = lda[bow]\n",
    "#lda.show_topics(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(freqs, bins=20)\n",
    "plt.title('Распределение относительных частот токенов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели на PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(UNIQUE_WORDS_N, UNIQUE_LABELS_N)\n",
    "\n",
    "scheduler = lambda optim: \\\n",
    "    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "best_val_loss, best_model = train_eval_loop(model=model,\n",
    "                                            train_dataset=train_dataset,\n",
    "                                            val_dataset=test_dataset,\n",
    "                                            criterion=F.cross_entropy,\n",
    "                                            lr=1e-1,\n",
    "                                            epoch_n=200,\n",
    "                                            batch_size=32,\n",
    "                                            l2_reg_alpha=0,\n",
    "                                            lr_scheduler_ctor=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_pred = predict_with_model(best_model, train_dataset)\n",
    "\n",
    "train_loss = F.cross_entropy(torch.from_numpy(train_pred),\n",
    "                             torch.from_numpy(train_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "test_pred = predict_with_model(best_model, test_dataset)\n",
    "\n",
    "test_loss = F.cross_entropy(torch.from_numpy(test_pred),\n",
    "                            torch.from_numpy(test_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], test_pred.argmax(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Альтернативная реализация на scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_pipeline = Pipeline((('vect', TfidfVectorizer()),\n",
    "                             ('cls', LogisticRegression())))\n",
    "sklearn_pipeline.fit(train_source['data'], train_source['target']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_train_pred = sklearn_pipeline.predict_proba(train_source['data'])\n",
    "sklearn_train_loss = F.cross_entropy(torch.from_numpy(sklearn_train_pred),\n",
    "                                                 torch.from_numpy(train_source['target']))\n",
    "print('Среднее значение функции потерь на обучении', float(sklearn_train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], sklearn_train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "sklearn_test_pred = sklearn_pipeline.predict_proba(test_source['data'])\n",
    "sklearn_test_loss = F.cross_entropy(torch.from_numpy(sklearn_test_pred),\n",
    "                                                torch.from_numpy(test_source['target']))\n",
    "print('Среднее значение функции потерь на валидации', float(sklearn_test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], sklearn_test_pred.argmax(-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
