{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\El Tuko\\anaconda3\\envs\\pykeen\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pykeen\n",
    "import torch\n",
    "import requests\n",
    "import seaborn as sns\n",
    "\n",
    "from rdflib import Graph, Literal, RDF, URIRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from seaborn) (1.22.3)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\el tuko\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = requests.get(\"https://raw.githubusercontent.com/dimour-itmo/KnowledgeGrpahCourse/master/Practice/P41142/elya-mamedova/GFResult.owl\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "graph.parse(file, format=\"turtle\")\n",
    "triples = np.array(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "tf = TriplesFactory.from_labeled_triples(triples)\n",
    "X_train, X_test = tf.split(0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2492, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 3347917914.\n",
      "No cuda devices were available. The model runs on CPU\n",
      "C:\\Users\\El Tuko\\anaconda3\\envs\\pykeen\\lib\\site-packages\\pykeen\\nn\\representation.py:369: UserWarning: Directly use Embedding.max_id instead of num_embeddings.\n",
      "  warnings.warn(f\"Directly use {self.__class__.__name__}.max_id instead of num_embeddings.\")\n",
      "C:\\Users\\El Tuko\\anaconda3\\envs\\pykeen\\lib\\site-packages\\pykeen\\nn\\representation.py:375: UserWarning: Directly use Embedding.shape instead of num_embeddings.\n",
      "  warnings.warn(f\"Directly use {self.__class__.__name__}.shape instead of num_embeddings.\")\n",
      "Training epochs on cpu:   0%|          | 0/50 [00:00<?, ?epoch/s]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%|▏         | 1/50 [00:00<00:08,  5.69epoch/s, loss=0.00481, prev_loss=nan]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%|▍         | 2/50 [00:00<00:08,  5.46epoch/s, loss=0.00454, prev_loss=0.00481]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████| 8/8 [00:00<00:00, 79.56batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%|▌         | 3/50 [00:00<00:09,  4.71epoch/s, loss=0.00426, prev_loss=0.00454]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%|▊         | 4/50 [00:00<00:09,  4.82epoch/s, loss=0.00416, prev_loss=0.00426]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%|█         | 5/50 [00:00<00:08,  5.21epoch/s, loss=0.00386, prev_loss=0.00416]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%|█▏        | 6/50 [00:01<00:08,  5.22epoch/s, loss=0.00354, prev_loss=0.00386]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|█▍        | 7/50 [00:01<00:07,  5.49epoch/s, loss=0.00342, prev_loss=0.00354]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|█▌        | 8/50 [00:01<00:07,  5.58epoch/s, loss=0.00318, prev_loss=0.00342]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|█▊        | 9/50 [00:01<00:07,  5.23epoch/s, loss=0.0031, prev_loss=0.00318] \n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|██        | 10/50 [00:01<00:07,  5.22epoch/s, loss=0.00297, prev_loss=0.0031]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|██▏       | 11/50 [00:02<00:07,  5.25epoch/s, loss=0.00274, prev_loss=0.00297]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|██▍       | 12/50 [00:02<00:07,  5.33epoch/s, loss=0.00268, prev_loss=0.00274]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|██▌       | 13/50 [00:02<00:06,  5.54epoch/s, loss=0.00248, prev_loss=0.00268]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|██▊       | 14/50 [00:02<00:06,  5.66epoch/s, loss=0.00234, prev_loss=0.00248]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|███       | 15/50 [00:02<00:06,  5.76epoch/s, loss=0.00225, prev_loss=0.00234]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|███▏      | 16/50 [00:02<00:05,  5.86epoch/s, loss=0.00216, prev_loss=0.00225]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|███▍      | 17/50 [00:03<00:05,  5.62epoch/s, loss=0.00201, prev_loss=0.00216]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████| 8/8 [00:00<00:00, 75.26batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|███▌      | 18/50 [00:03<00:06,  5.26epoch/s, loss=0.00195, prev_loss=0.00201]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|███▊      | 19/50 [00:03<00:05,  5.22epoch/s, loss=0.00183, prev_loss=0.00195]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████| 8/8 [00:00<00:00, 53.59batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|████      | 20/50 [00:03<00:06,  4.49epoch/s, loss=0.00176, prev_loss=0.00183]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  42%|████▏     | 21/50 [00:04<00:07,  4.04epoch/s, loss=0.00166, prev_loss=0.00176]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████| 8/8 [00:00<00:00, 76.91batch/s]\u001b[A\n",
      "Training epochs on cpu:  44%|████▍     | 22/50 [00:04<00:07,  3.66epoch/s, loss=0.00155, prev_loss=0.00166]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  88%|████████▊ | 7/8 [00:00<00:00, 64.32batch/s]\u001b[A\n",
      "Training epochs on cpu:  46%|████▌     | 23/50 [00:04<00:07,  3.79epoch/s, loss=0.00156, prev_loss=0.00155]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  48%|████▊     | 24/50 [00:04<00:06,  4.14epoch/s, loss=0.00149, prev_loss=0.00156]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  50%|█████     | 25/50 [00:05<00:05,  4.47epoch/s, loss=0.00133, prev_loss=0.00149]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  52%|█████▏    | 26/50 [00:05<00:05,  4.77epoch/s, loss=0.00127, prev_loss=0.00133]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  54%|█████▍    | 27/50 [00:05<00:04,  4.84epoch/s, loss=0.00123, prev_loss=0.00127]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  56%|█████▌    | 28/50 [00:05<00:04,  5.07epoch/s, loss=0.00116, prev_loss=0.00123]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  58%|█████▊    | 29/50 [00:05<00:04,  5.20epoch/s, loss=0.00103, prev_loss=0.00116]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  60%|██████    | 30/50 [00:05<00:03,  5.44epoch/s, loss=0.00111, prev_loss=0.00103]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  62%|██████▏   | 31/50 [00:06<00:03,  5.54epoch/s, loss=0.001, prev_loss=0.00111]  \n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  64%|██████▍   | 32/50 [00:06<00:03,  5.72epoch/s, loss=0.000967, prev_loss=0.001]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  66%|██████▌   | 33/50 [00:06<00:03,  5.58epoch/s, loss=0.000912, prev_loss=0.000967]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  68%|██████▊   | 34/50 [00:06<00:03,  5.25epoch/s, loss=0.000908, prev_loss=0.000912]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  70%|███████   | 35/50 [00:06<00:02,  5.13epoch/s, loss=0.000855, prev_loss=0.000908]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  72%|███████▏  | 36/50 [00:07<00:02,  5.22epoch/s, loss=0.000806, prev_loss=0.000855]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  74%|███████▍  | 37/50 [00:07<00:02,  5.46epoch/s, loss=0.000821, prev_loss=0.000806]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  76%|███████▌  | 38/50 [00:07<00:02,  5.68epoch/s, loss=0.000763, prev_loss=0.000821]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  78%|███████▊  | 39/50 [00:07<00:02,  5.43epoch/s, loss=0.000751, prev_loss=0.000763]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  80%|████████  | 40/50 [00:07<00:01,  5.45epoch/s, loss=0.000722, prev_loss=0.000751]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  82%|████████▏ | 41/50 [00:07<00:01,  5.63epoch/s, loss=0.000647, prev_loss=0.000722]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  84%|████████▍ | 42/50 [00:08<00:01,  5.74epoch/s, loss=0.000639, prev_loss=0.000647]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  86%|████████▌ | 43/50 [00:08<00:01,  5.74epoch/s, loss=0.000593, prev_loss=0.000639]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  88%|████████▊ | 44/50 [00:08<00:01,  5.83epoch/s, loss=0.00061, prev_loss=0.000593] \n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  90%|█████████ | 45/50 [00:08<00:00,  5.78epoch/s, loss=0.000528, prev_loss=0.00061]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  92%|█████████▏| 46/50 [00:08<00:00,  5.71epoch/s, loss=0.000489, prev_loss=0.000528]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  94%|█████████▍| 47/50 [00:09<00:00,  5.82epoch/s, loss=0.000517, prev_loss=0.000489]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  96%|█████████▌| 48/50 [00:09<00:00,  5.67epoch/s, loss=0.000495, prev_loss=0.000517]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████| 8/8 [00:00<00:00, 69.90batch/s]\u001b[A\n",
      "Training epochs on cpu:  98%|█████████▊| 49/50 [00:09<00:00,  4.44epoch/s, loss=0.000503, prev_loss=0.000495]\n",
      "Training batches on cpu:   0%|          | 0/8 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu: 100%|██████████| 50/50 [00:09<00:00,  5.13epoch/s, loss=0.000529, prev_loss=0.000503]\n",
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "Evaluating on cpu: 100%|██████████| 499/499 [00:00<00:00, 1.02ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.51s seconds\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "train_result = pipeline(\n",
    "    model='TransE',  \n",
    "    training=X_train,\n",
    "    testing=X_test,\n",
    "    epochs=50,\n",
    "    filter_validation_when_testing=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05086166431846151"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.get_metric(\"mrr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Side</th>\n",
       "      <th>Type</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>median_rank</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tail</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>median_rank</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>both</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>median_rank</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>head</td>\n",
       "      <td>realistic</td>\n",
       "      <td>median_rank</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>median_rank</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.224623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>both</td>\n",
       "      <td>realistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.141398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>head</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.058129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tail</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.224623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>both</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.141398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Side         Type              Metric       Value\n",
       "0    head   optimistic         median_rank  166.000000\n",
       "1    tail   optimistic         median_rank   44.000000\n",
       "2    both   optimistic         median_rank   89.000000\n",
       "3    head    realistic         median_rank  166.000000\n",
       "4    tail    realistic         median_rank   44.000000\n",
       "..    ...          ...                 ...         ...\n",
       "202  tail    realistic  adjusted_hits_at_k    0.224623\n",
       "203  both    realistic  adjusted_hits_at_k    0.141398\n",
       "204  head  pessimistic  adjusted_hits_at_k    0.058129\n",
       "205  tail  pessimistic  adjusted_hits_at_k    0.224623\n",
       "206  both  pessimistic  adjusted_hits_at_k    0.141398\n",
       "\n",
       "[207 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.metric_results.to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykeen",
   "language": "python",
   "name": "pykeen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
